---
title: "Sampling from the Wischart distribution."
description: "An approach to sample from the Wischart distribtuion."
date: 2020-02-24
categories:
  - R
  - Statistical simulations
  - Wishart distribution  
execute: 
  warning: false
  message: false  
---

## Wishart distribution

*The **Wishart distribution** is a family of probability distributions defined over **symmetric**, **nonnegative-definite** matrix-valued random variables ("random matrices"). These distributions are of great importance in the estimation of covariance matrices in multivariate statistics.*

Suppose $\boldsymbol{X}_{p\times n} = \left(\boldsymbol{X}^{(1)}, \ldots, \boldsymbol{X}^{n}\right)$ is a $p\times n$ matrix, each column of which is independently drawn from a $p$-variate normal distribution with zero mean, i.e.

$$
  \boldsymbol{X}^{(j)} \sim N(0, \boldsymbol{V}), \quad j = 1, \ldots, n,
$$ {#eq-multivariate-normal}

where $\boldsymbol{V}$ is a $p\times p$ covariance matrix. Then a ***random matrix-valued variable***

$$
  \boldsymbol{S} = \boldsymbol{X}\cdot \boldsymbol{X}'
$$ {#eq-rnd-matrix}

follows Wishart distribution $W_p(\boldsymbol{V}, n)$. It has the following numerical characteristics:

-   Expected value: $$
    \text{E}\left[\boldsymbol{S}\right] = n\boldsymbol{V}.
    $$ {#eq-wishart-mean}

-   Variance: $$
    \text{Var}\left[\boldsymbol{S}\right] = n\left(\boldsymbol{V}^2 + diag(\boldsymbol{V})\cdot diag(\boldsymbol{V})'\right), \: diag(\boldsymbol{V}) = \left(\boldsymbol{V}_{11}, \ldots, \boldsymbol{V}_{pp}\right),
    $$ {#eq-wishart-variance}

where elements of $\boldsymbol{V}^2$ are obtained as squares of the corresponding elements of $\boldsymbol{V}$.

We are interested in sampling random matrices with the mean value equal to $\boldsymbol{V}$, i.e.

$$
  \boldsymbol{S}_{1}, \boldsymbol{S}_{2}, \ldots, \sim W_p(\boldsymbol{V}, 1).
$$ {#eq-wishart-sample}

A sample-point from the distribution $W_p(\boldsymbol{V}, 1)$ can be drawn by doing the following steps:

1.  Sample multi-variate ($p$-variate) random variable $\boldsymbol{X}\sim N(0, \boldsymbol{V})$:

    -   make a Choletsky decomposition of $\boldsymbol{V}$, i.e. $\boldsymbol{V} = \boldsymbol{L}\cdot \boldsymbol{L}'.$
    -   sample multi-variate ($p$-variate) random variable $\boldsymbol{Z}\sim N(0, \boldsymbol{I}).$
    -   $\boldsymbol{X} = \boldsymbol{L}\cdot \boldsymbol{Z}.$

2.  $\boldsymbol{S} = \boldsymbol{X}\cdot \boldsymbol{X}'.$

## R code to perform the procedure

```{r}
#| label: wishart-sampling

# loading pipe %>%
library(magrittr)

# loading map_ function family
library(purrr)

# function to sample a single observation from the Wishart distribution, 
# given parameters V, n

r1wishart <- function(V, n = 1){
  p <- nrow(V)

  # Choletsky decomposition 
  L <- t(chol(V))
  
  X <- map(seq_len(n), ~ { 
    Z <- rnorm(p)
    L%*%Z
  }) %>%
  unlist() %>%
  matrix(ncol = n, byrow = FALSE)
  X%*%t(X) 
}

# function to sample nsmp observations from the Wishart distribution, 
# given parameters V, n

sample_wishart <- function(nsmp, V, n = 1){
  map(seq_len(nsmp), ~ r1wishart(V, n)) 
}
```

## Test example

```{r}
#| label: example-wishart
# variances
omega <- c(1, 2, 3)

# correlation matrix
rho <- rbind(
  c(1, 0.2, 0.7),
  c(0.2, 1, 0.45),
  c(0.7, 0.45, 1) 
)

# covariance matrix
V <- rho*sqrt(cbind(omega)%*%rbind(omega)) 

# number of sample points
nsmp <- 10000

# sampling
W <- sample_wishart(nsmp, V)

# calculating the sample mean. We expect that it is approximately equal to V
sample_mean <- reduce(W, `+`)/nsmp 

# printing out the sample mean
print(sample_mean) 

# printing out the true mean
print(V) 


# calculating the sample variance. 
# We expect that it is approximately equal to V^2 + diag(V)%*%t(diag(V))

sample_var <- map(W, ~ .^2) %>% 
  reduce(`+`) %>% 
  '/'(nsmp) %>% 
  '-'(sample_mean^2) 

# printing out the result
print(round(nsmp/(nsmp-1)*sample_var, 2)) 

# printing out the true variance
print(V^2 + cbind(diag(V))%*%rbind(diag(V)))
```
